{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code extracts the table with country information from: https://en.wikipedia.org/wiki/ISO_3166-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtaining country names\n",
    "\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/ISO_3166-1\"\n",
    "#We use this url as it will give us country names and iso codes that we can use for the visualisation\n",
    "\n",
    "pageFile = urllib2.urlopen(wiki_url)\n",
    "pageHtml = pageFile.read()\n",
    "pageFile.close()\n",
    "countries_soup = BeautifulSoup(\"\".join(pageHtml))\n",
    "countries = countries_soup.find(\"table\",attrs={\"class\":\"wikitable\"}).findAll(\"tr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTextFromArray(soup_item):\n",
    "    return [s.get_text() for s in soup_item]\n",
    "\n",
    "\n",
    "def saveCountryData(countries,filename):\n",
    "    full_data = []\n",
    "    # extract column names\n",
    "    column_names = getTextFromArray(countries[0].findAll(\"th\"))\n",
    "    \n",
    "    # open file and write column names\n",
    "    f = open(filename,'w')\n",
    "    f.write( \",\".join(column_names) + \"\\n\")\n",
    "    \n",
    "    # remove the column names from the data object\n",
    "    countries = countries[1:]\n",
    "    \n",
    "    # loop over countries and write out details to file\n",
    "    for country in countries:\n",
    "        data = getTextFromArray(country.findAll(\"td\"))\n",
    "        f.write( \",\".join(data).encode('utf-8').strip() + \"\\n\")\n",
    "        full_data.append(data)\n",
    "    # close the file\n",
    "    f.close()\n",
    "    \n",
    "    return full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save country data\n",
    "country_data = saveCountryData(countries,\"countries_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exported csv file has a row for every country, with columns matching the columns in the wikipedia table.\n",
    "We can then use the iso codes for each country to identify countries on a d3 map.\n",
    "The only problem is that the country names in this table do not necessarily match the names of countries in other wikipedia pages. For example, Cote d'Ivoire and Ivory Coast are used interchangeably in wikipedia without there being a country match to tell us that they refer to the same place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
