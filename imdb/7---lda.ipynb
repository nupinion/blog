{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'seaborn-darkgrid', u'seaborn-notebook', u'classic', u'seaborn-ticks', u'grayscale', u'bmh', u'seaborn-talk', u'dark_background', u'ggplot', u'fivethirtyeight', u'seaborn-colorblind', u'seaborn-deep', u'seaborn-whitegrid', u'seaborn-bright', u'seaborn-poster', u'seaborn-muted', u'seaborn-paper', u'seaborn-white', u'seaborn-pastel', u'seaborn-dark', u'seaborn-dark-palette']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print plt.style.available\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------- #\n",
    "def fnShowNumberOfReviews(MOVIES):\n",
    "    s = 0\n",
    "    for m in MOVIES:\n",
    "        if 'reviews' in m:\n",
    "            # print m['name'], len(m['reviews'])\n",
    "            s += len(m['reviews'])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return s\n",
    "    # --------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 9869 movies in the dataset.\n",
      "\n",
      "Number of reviews available: 436623\n"
     ]
    }
   ],
   "source": [
    "MOVIES = json.load(open('../../data-blog---list_of_movies_v2-v650.json','r'))\n",
    "\n",
    "print 'We have {} movies in the dataset.'.format(len(MOVIES))\n",
    "print '\\nNumber of reviews available: {}'.format(fnShowNumberOfReviews(MOVIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'director', u'description', u'num_reviews_pages', u'reviews', u'stars', u'link', u'poster_desc', u'year', u'poster_img', u'name']\n"
     ]
    }
   ],
   "source": [
    "print MOVIES[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436623\n",
      "{\n",
      "    \"movie\": \"Pulp Fiction\", \n",
      "    \"review_content\": \"\\nPulp Fiction may be the single best film ever made, and quite\\nappropriately it is by one of the most creative directors of all time,\\nQuentin Tarantino. This movie is amazing from the beginning definition\\nof pulp to the end credits and boasts one of the best casts ever\\nassembled with the likes of Bruce Willis, Samuel L. Jackson, John\\nTravolta, Uma Thurman, Harvey Keitel, Tim Roth and Christopher Walken.\\nThe dialog is surprisingly humorous for this type of film, and I think\\nthat's what has made it so successful. Wrongfully denied the many\\nOscars it was nominated for, Pulp Fiction is by far the best film of\\nthe 90s and no Tarantino film has surpassed the quality of this movie\\n(although Kill Bill came close). As far as I'm concerned this is the\\ntop film of all-time and definitely deserves a watch if you haven't\\nseen it.\\n\", \n",
      "    \"review_rating\": 10, \n",
      "    \"review_title\": \"Unbelievable.\", \n",
      "    \"link\": \"/title/tt0110912/\", \n",
      "    \"user_href\": \"/user/ur4568292/\", \n",
      "    \"user_name\": \"discoelephant64\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "REVIEWS = []\n",
    "\n",
    "for movie in MOVIES:\n",
    "    if 'reviews' in movie:\n",
    "        reviews_tmp = []\n",
    "        for r in movie['reviews']:\n",
    "            r['movie'] = movie['name']\n",
    "            r['link'] = movie['link']\n",
    "            reviews_tmp.append(r)\n",
    "        REVIEWS += reviews_tmp\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print len(REVIEWS)\n",
    "print json.dumps(REVIEWS[3],indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                link         movie  \\\n",
      "0  /title/tt0110912/  Pulp Fiction   \n",
      "1  /title/tt0110912/  Pulp Fiction   \n",
      "\n",
      "                                      review_content  review_rating  \\\n",
      "0  \\nOne of the early scenes in \"Pulp Fiction\" fe...             10   \n",
      "1  \\nTo put this in context, I am 34 years old an...             10   \n",
      "\n",
      "                        review_title         user_href  \\\n",
      "0  The masterpiece without a message  /user/ur0556667/   \n",
      "1                    Simply The Best  /user/ur1515595/   \n",
      "\n",
      "                   user_name  \n",
      "0  kylopod (kylopod@aol.com)  \n",
      "1                  wolvesrug  \n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(REVIEWS)\n",
    "\n",
    "print data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets not hold massive objects in memory.\n",
    "MOVIES = REVIEWS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Select Sub-set\n",
    "\n",
    "Since the dataset is to big..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    99088\n",
      "8     52668\n",
      "9     51853\n",
      "7     40920\n",
      "1     32887\n",
      "6     28687\n",
      "5     21950\n",
      "4     16749\n",
      "3     15982\n",
      "2     13226\n",
      "Name: review_rating, dtype: int64\n",
      "\n",
      "62613\n"
     ]
    }
   ],
   "source": [
    "print data.review_rating.value_counts()\n",
    "print '\\n', np.sum(data.review_rating.isnull())\n",
    "\n",
    "data.review_rating.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8733 427890\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "ixs = StratifiedShuffleSplit(data.review_rating.values, n_iter=1, test_size=0.98, train_size=None, random_state=None)\n",
    "\n",
    "print len(ixs)\n",
    "train_ix, test_ix = [(i[0],i[1]) for i in ixs ][0]\n",
    "print len(train_ix), len(test_ix)\n",
    "ixs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Tokenizing Text\n",
    "\n",
    "Using the standard NLTK Tokenize and some extra functions.\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import reuters \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now']\n"
     ]
    }
   ],
   "source": [
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "print len(cachedStopWords), cachedStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pulp Fiction may be the single best film ever made, and quite\n",
      "appropriately it is by one of the most creative directors of all time,\n",
      "Quentin Tarantino. This movie is amazing from the beginning definition\n",
      "of pulp to the end credits and boasts one of the best casts ever\n",
      "assembled with the likes of Bruce Willis, Samuel L. Jackson, John\n",
      "Travolta, Uma Thurman, Harvey Keitel, Tim Roth and Christopher Walken.\n",
      "The dialog is surprisingly humorous for this type of film, and I think\n",
      "that's what has made it so successful. Wrongfully denied the many\n",
      "Oscars it was nominated for, Pulp Fiction is by far the best film of\n",
      "the 90s and no Tarantino film has surpassed the quality of this movie\n",
      "(although Kill Bill came close). As far as I'm concerned this is the\n",
      "top film of all-time and definitely deserves a watch if you haven't\n",
      "seen it.\n",
      "\n",
      "NLTK Tokenize: \n",
      "[u'Pulp', u'Fiction', u'may', u'be', u'the', u'single', u'best', u'film', u'ever', u'made', u',', u'and', u'quite', u'appropriately', u'it', u'is', u'by', u'one', u'of', u'the', u'most', u'creative', u'directors', u'of', u'all', u'time', u',', u'Quentin', u'Tarantino', u'.', u'This', u'movie', u'is', u'amazing', u'from', u'the', u'beginning', u'definition', u'of', u'pulp', u'to', u'the', u'end', u'credits', u'and', u'boasts', u'one', u'of', u'the', u'best', u'casts', u'ever', u'assembled', u'with', u'the', u'likes', u'of', u'Bruce', u'Willis', u',', u'Samuel', u'L.', u'Jackson', u',', u'John', u'Travolta', u',', u'Uma', u'Thurman', u',', u'Harvey', u'Keitel', u',', u'Tim', u'Roth', u'and', u'Christopher', u'Walken', u'.', u'The', u'dialog', u'is', u'surprisingly', u'humorous', u'for', u'this', u'type', u'of', u'film', u',', u'and', u'I', u'think', u'that', u\"'s\", u'what', u'has', u'made', u'it', u'so', u'successful', u'.', u'Wrongfully', u'denied', u'the', u'many', u'Oscars', u'it', u'was', u'nominated', u'for', u',', u'Pulp', u'Fiction', u'is', u'by', u'far', u'the', u'best', u'film', u'of', u'the', u'90s', u'and', u'no', u'Tarantino', u'film', u'has', u'surpassed', u'the', u'quality', u'of', u'this', u'movie', u'(', u'although', u'Kill', u'Bill', u'came', u'close', u')', u'.', u'As', u'far', u'as', u'I', u\"'m\", u'concerned', u'this', u'is', u'the', u'top', u'film', u'of', u'all-time', u'and', u'definitely', u'deserves', u'a', u'watch', u'if', u'you', u\"haven't\", u'seen', u'it', u'.']\n",
      "\n",
      "Custom Tokenize: \n",
      "[u'pulp', u'fiction', u'may', u'singl', u'best', u'film', u'ever', u'made', u'quit', u'appropri', u'one', u'creativ', u'director', u'time', u'quentin', u'tarantino', u'movi', u'amaz', u'begin', u'definit', u'pulp', u'end', u'credit', u'boast', u'one', u'best', u'cast', u'ever', u'assembl', u'like', u'bruce', u'willi', u'samuel', u'jackson', u'john', u'travolta', u'uma', u'thurman', u'harvey', u'keitel', u'tim', u'roth', u'christoph', u'walken', u'dialog', u'surprisingli', u'humor', u'type', u'film', u'think', u'made', u'success', u'wrong', u'deni', u'mani', u'oscar', u'nomin', u'pulp', u'fiction', u'far', u'best', u'film', u'tarantino', u'film', u'surpass', u'qualiti', u'movi', u'although', u'kill', u'bill', u'came', u'close', u'far', u'concern', u'top', u'film', u'all-tim', u'definit', u'deserv', u'watch', u\"haven't\", u'seen']\n"
     ]
    }
   ],
   "source": [
    "# Define the tokenize function.\n",
    "def tokenize(text):\n",
    "    # Define the min-length for a word. We will disregard all words under min-length.\n",
    "    min_length = 3\n",
    "    # Use NLTK Tokenize and convert everything to lowercase.\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    # Remove all stopwords from the text by using NLTK Stopwords.\n",
    "    words = [word for word in words if word not in cachedStopWords]\n",
    "    # Stem the words using NLTK PorterStemmer.\n",
    "    #tokens = (list(map(lambda token: PorterStemmer().stem(token), words)))\n",
    "    tokens = [PorterStemmer().stem(w) for w in words] \n",
    "    # Filter out words based on characters and length.\n",
    "    p = re.compile('[a-zA-Z]+')\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token)>=min_length, tokens))\n",
    "    # Done, return the list.\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "text = data.ix[3].review_content\n",
    "print text\n",
    "print 'NLTK Tokenize: \\n{}'.format(word_tokenize(text))\n",
    "print '\\nCustom Tokenize: \\n{}'.format(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.9 s, sys: 610 ms, total: 53.6 s\n",
      "Wall time: 53.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize at 0x14922eb18>, vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CountVect = CountVectorizer(\n",
    "    tokenizer=tokenize, # Our custom tokenize function\n",
    "    min_df=3, # The feature needs to be present in at least 3 documents\n",
    "    max_df=0.90, # The feature cannot be in more than 90% of the documents.\n",
    "    \n",
    ")\n",
    "\n",
    "%time CountVect.fit(data.ix[train_ix].review_content.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14680\n",
      "[u'a**', u'a++', u'a-list', u'a-plenti', u'a-team', u'a.i', u'a.i.', u'a.k.a', u'aang', u'aaron', u'abandon', u'abbi', u'abc', u'abdomen', u'abduct', u'abe', u'abel', u'aberr', u'abet', u'abhor']\n"
     ]
    }
   ],
   "source": [
    "# Get all the features from the trained representer.\n",
    "all_features = CountVect.get_feature_names()\n",
    "\n",
    "print len(all_features)\n",
    "print all_features[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 632 ms, total: 53.8 s\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%time train_counts = CountVect.transform(data.ix[train_ix].review_content.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 50s, sys: 9.8 s, total: 5min 59s\n",
      "Wall time: 6min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=100, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=10, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=100, learning_method='online', learning_offset=50.)\n",
    "\n",
    "%time lda.fit(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "comic superhero spider-man hulk peter iron man parker aveng spiderman marvel villain hero green book raimi bruce suit lee sam\n",
      "1\n",
      "burton depp johnni comedi pirat cameron downey norton toni termin laugh edward jr. hilari ben man robert stiller ferrel sarah\n",
      "2\n",
      "toy pixar pitt brad ocean clooney andi woodi vega spacey stori transform lantern kevin voic sam julia beauti sun buzz\n",
      "3\n",
      "film one charact n't like time make stori movi get also would scene way take action even well work world\n",
      "4\n",
      "movi n't like film good one see realli watch great time would think make first charact get scene much stori\n",
      "5\n",
      "war x-men vietnam soldier vampir comic mutant wolverin hugh donni trek jackman singer patrick diamond bryan seri russian jean apocalyps\n",
      "6\n",
      "war star ring luca jackson superman episod battl trilog lord jone anakin return hobbit indiana effect two jar peter book\n",
      "7\n",
      "neeson liam murphi terri monkey gilliam soderbergh oskar parnassu scarecrow cillian byrn imaginarium gina olympu mitch brazil perseu poseidon focker\n",
      "8\n",
      "tarantino best jack perform play oscar role actor nicholson brother bill dicaprio nomin kubrick cruis pulp scorses black wife quentin\n",
      "9\n",
      "batman dark joker knight nolan spielberg best ledger perform bruce bale heath holm begin christian wayn christoph cruis gotham tom\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print topic_idx,\n",
    "    print \" \".join([all_features[i] for i in topic.argsort()[:-20 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
