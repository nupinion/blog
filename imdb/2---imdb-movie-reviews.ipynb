{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `movie_id` from IMDB and create the reviews-URL. The next step is to load the page, get the contents and soup it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_id = 'tt1596363'\n",
    "\n",
    "url = 'http://www.imdb.com/title/' + movie_id + '/reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luuk/pyEnv/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html.parser\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8',\n",
    "       'Connection': 'keep-alive'}\n",
    "\n",
    "def getUrlSoup(url,hdr):\n",
    "    req1 = urllib2.Request(url, headers=hdr)\n",
    "    page = urllib2.urlopen(req1)\n",
    "    content = page.read()\n",
    "    soup = BeautifulSoup(content)\n",
    "    return soup\n",
    "    \n",
    "soup = getUrlSoup(url,hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the main block and find out how many pages there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_block = (soup.body.find('div', attrs={'class':'reviews'})\n",
    "                       .find('div', attrs={'id':'tn15main'})\n",
    "                       .find('div', attrs={'id':'tn15content'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21 pages to get the reviews from\n"
     ]
    }
   ],
   "source": [
    "num_pages = int(main_block.findAll('table')[1]\n",
    "                          .find('td',attrs={'nowrap':'1'}).get_text().split(' of ')[1].rstrip(':'))\n",
    "\n",
    "print 'There are {} pages to get the reviews from'.format(num_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the pages and grab the reviews. We'll store all of them in the `reviews` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getReviews(main_block, reviews_obj=None):\n",
    "    \n",
    "    assert reviews_obj is not None\n",
    "    \n",
    "    # Treat it as a massive block of text and split it on the horizontal lines.\n",
    "    reviews_block = re.split(r\"<hr[^>]*>\", str(main_block))\n",
    "    \n",
    "    # Iterate over all the reviews.\n",
    "    # NOTE: The indexing is dubious here...\n",
    "    for r in reviews_block[1:-3]:\n",
    "        \n",
    "        # Soup the block of html-code-text\n",
    "        soup_review = BeautifulSoup(r)\n",
    "        soup_review_header = soup_review.find('div')\n",
    "        \n",
    "        # Create an empty dictionary to hold the review.\n",
    "        review = dict()\n",
    "        \n",
    "        # Get the user-name, user-link for the reviewer.\n",
    "        review['user_name'] = soup_review_header.findAll('a')[1].get_text()\n",
    "        review['user_href'] = soup_review_header.findAll('a')[1]['href']\n",
    "\n",
    "        # Try to get the rating.\n",
    "        soup_imgs = soup_review_header.findAll('img')\n",
    "        review['review_rating'] = None\n",
    "        if len(soup_imgs) > 1:\n",
    "            review['review_rating'] = int(soup_imgs[1]['alt'].split('/')[0])\n",
    "        \n",
    "        # Get the review title.\n",
    "        review['review_title'] = soup_review.find('h2').get_text()\n",
    "        \n",
    "        # Get the review content.\n",
    "        tmp_content = soup_review.findAll('p')\n",
    "        if len(tmp_content) > 1 and 'spoilers' in tmp_content[0].get_text():\n",
    "            review['review_content'] = tmp_content[1].get_text()\n",
    "        else:\n",
    "            review['review_content'] = tmp_content[0].get_text()\n",
    "        \n",
    "        # Get the review usefulness.\n",
    "        # review['review_useful'] = soup_review_header.find('small').get_text().split('people')[0].rstrip().lstrip()\n",
    "        \n",
    "        reviews_obj.append(review)\n",
    "        \n",
    "    # Done. Return the reviews_obj\n",
    "    return reviews_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to grab the reviews for this movie...\n",
      "\n",
      "Getting the contents for page 1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . 14 . 15 . 16 . 17 . 18 . 19 . 20 . 21 . \n",
      "\n",
      "Obtained 203 reviews for this movie\n"
     ]
    }
   ],
   "source": [
    "print 'Starting to grab the reviews for this movie...'\n",
    "\n",
    "# Create an empty array to hold all the reviews.\n",
    "REVIEWS = []\n",
    "\n",
    "print '\\nGetting the contents for page',\n",
    "for i in range(1,num_pages+1):\n",
    "    \n",
    "    # If this is the first page, we don't need to load the new page.\n",
    "    if i == 1:\n",
    "        REVIEWS = getReviews(main_block,REVIEWS)\n",
    "    \n",
    "    # We need to grab the contents for the next page.\n",
    "    else:\n",
    "        page_soup = getUrlSoup(url + '?start=' + str(10*(i-1)), hdr)\n",
    "        main_block = (page_soup.body.find('div', attrs={'class':'reviews'})\n",
    "                                    .find('div', attrs={'id':'tn15main'})\n",
    "                                    .find('div', attrs={'id':'tn15content'}))\n",
    "        REVIEWS = getReviews(main_block,REVIEWS)\n",
    "    \n",
    "    print i, '.',\n",
    "\n",
    "\n",
    "print '\\n\\nObtained {} reviews for this movie'.format(len(REVIEWS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"review_content\": \"\\nOK, so i've watched this in movie hoping to understand the main story\\nof '08 crisis. Instead I get a 2h movie full of boring terms and people\\nacting like they are smart and \\\"gtfo attitude\\\". I've tried so hard to\\nmaintain the course of my brain ,to pay attention to the story, but the\\nreally annoying terminology and economical jargon kept me away from\\nconstructing any bond with an actor or a situation. I am thinking: what\\nif a broker watch this movie...what he will think about it ? It will be\\ninteresting or probably will say that the movie it's not accurate like\\npretty much every movie lately. Seriously, this production don't even\\nput Chris bale in a good light... because he is just a \\\"mad pawn \\\"\\nright there talking about banks and sums. His role don't put him in the\\nright place for showing his potential. Crude !\\n\", \n",
      "        \"review_rating\": 5, \n",
      "        \"user_href\": \"/user/ur29880112/\", \n",
      "        \"review_title\": \"Boring Apocalypse\", \n",
      "        \"user_name\": \"ave_claudiu\"\n",
      "    }, \n",
      "    {\n",
      "        \"review_content\": \"\\nThe thing i liked the most about this movie is the way the story is\\ntold. All the resources the director chose tell it and the way it all\\ncomes together in a way that the audience with no particular formation\\nor even interest in the financial market ends up understanding it all.\\nBravo, bravo to this gem from a surprisingly inexperienced director in\\nthe gender. It's the story of those few who saw the \\\"financial bubble\\\"\\nthat the mortgage market was in the US during the last years of the\\n90's and decided to \\\"bet\\\" against it.Said in those terms sounds like a\\npretty boring movie to watch but don't be deceive. With and outstanding\\ncast, an incredible story and a new, kind of revolutionary, way of\\ntelling it this movie has no way of failing the viewers. My personal\\nfavorite to win the Oscar this year...\\n\", \n",
      "        \"review_rating\": 9, \n",
      "        \"user_href\": \"/user/ur63859731/\", \n",
      "        \"review_title\": \"An unbelievable story greatly told\", \n",
      "        \"user_name\": \"Maria Aristimu\\u00c3\\u00b1o\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(REVIEWS[97:99],indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
